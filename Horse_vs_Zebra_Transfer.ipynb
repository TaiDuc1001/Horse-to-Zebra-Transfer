{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Vz-OlT8J9E3h",
        "40Yt3-li9Ha1",
        "pgMLl1Xi_xOK"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a78359a476ce4b0bbf44835e76e0dc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_506bfa02711446208ff80b3c8d38eff8",
              "IPY_MODEL_d0f3a0c4956843d3a4abaf457ce33da4"
            ],
            "layout": "IPY_MODEL_77b77566155c4d9fb1b6204601e3c7c2"
          }
        },
        "506bfa02711446208ff80b3c8d38eff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3daf742e8ae54f6584dadbd64051c1bb",
            "placeholder": "​",
            "style": "IPY_MODEL_0cdf3f7cfd4246f598d270e27375136f",
            "value": "58.365 MB of 58.365 MB uploaded\r"
          }
        },
        "d0f3a0c4956843d3a4abaf457ce33da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40ca3ec653384db0b18e269d4a7b2434",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_249816bf9e0047fdbcb8c1ec0b14a52c",
            "value": 1
          }
        },
        "77b77566155c4d9fb1b6204601e3c7c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3daf742e8ae54f6584dadbd64051c1bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cdf3f7cfd4246f598d270e27375136f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40ca3ec653384db0b18e269d4a7b2434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "249816bf9e0047fdbcb8c1ec0b14a52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaiDuc1001/Horse-to-Zebra-Transfer/blob/main/Horse_vs_Zebra_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install WandB"
      ],
      "metadata": {
        "id": "Vz-OlT8J9E3h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-3N43_0Arpre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0946cb-0990-48fd-fec2-9e315461939b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb --quiet\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3z3llxF-nkl",
        "outputId": "feae691a-aced-496b-bb06-cdcda60862f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ],
      "metadata": {
        "id": "40Yt3-li9Ha1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn.functional as F\n",
        "import torchsummary\n",
        "\n",
        "from PIL import Image\n",
        "import tqdm\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import wandb"
      ],
      "metadata": {
        "id": "oh4x6RaUryUr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config hyperparameters and project informations"
      ],
      "metadata": {
        "id": "XDVcQSrk9Jkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"GAN TYPE\": \"CycleGAN\",\n",
        "    \"DISCRIMINATOR ARCHITECTURE\": \"PatchGAN\",\n",
        "    \"GENERATOR ARCHITECTURE\": \"UNET\",\n",
        "    \"DATASET\": \"HORSE2ZEBRA\",\n",
        "    \"FEATURES\": 64,\n",
        "    \"EPOCHS\": 50,\n",
        "    \"BATCH_SIZE\": 1,\n",
        "    \"LEARNING_RATE\": 1e-5,\n",
        "    \"LAMBDA_CONSISTENCY\": 10,\n",
        "    \"LAMBDA_IDENTITY\": 5,\n",
        "    \"NUM_WORKERS\": 4,\n",
        "    \"DEVICE\": torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "}\n",
        "wandb.init(project=\"Horse_vs_Zebra_Transfer\", config=config)\n",
        "config = wandb.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544,
          "referenced_widgets": [
            "a78359a476ce4b0bbf44835e76e0dc2d",
            "506bfa02711446208ff80b3c8d38eff8",
            "d0f3a0c4956843d3a4abaf457ce33da4",
            "77b77566155c4d9fb1b6204601e3c7c2",
            "3daf742e8ae54f6584dadbd64051c1bb",
            "0cdf3f7cfd4246f598d270e27375136f",
            "40ca3ec653384db0b18e269d4a7b2434",
            "249816bf9e0047fdbcb8c1ec0b14a52c"
          ]
        },
        "id": "cSDi64GVs_Ah",
        "outputId": "94d65897-b700-4ee0-b933-1ef558f235fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:myevemws) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='58.345 MB of 58.345 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a78359a476ce4b0bbf44835e76e0dc2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Batch index</td><td>▁▁▂▂▃▃▄▅▅▆▆▆▇▇█▁▂▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▄▅▅▆▆</td></tr><tr><td>Discriminator Horse</td><td>▄▅▄▁▃▃▃█▅▇▂▅▅▄▃▆▄▃▆▄▃▅▆▅▃▅▄▄▅▃▅▅▄▅▆▄▄▃▁▂</td></tr><tr><td>Discriminator Zebra</td><td>▄▄▃▃▅▄▃▄▇▆▁▄▃▅▁▂▅▃▄▄▄█▃▃▁▄▆▃▄▄▃▄▅▄▃▃▃▄▂▁</td></tr><tr><td>Generator Horse</td><td>▆▅▇▆▇▅▇▁▄▃▆▆▆▅▆▄▅▇▅▄▅▅▃▆▆▅▄▆█▃▇▆▇▇▂▆█▅█▅</td></tr><tr><td>Generator Zebra</td><td>▃▂▂▆▂▅▃▄▁▂▄▃▃▂▆▄▃▂▂▅▂▂▄▄▅▂▅▂▃▅▅▃▃▂▇▃▁▁█▅</td></tr><tr><td>Horse Consistency</td><td>▄▃▅▁▄▂▅▅▂▄▇▃▆▃▄▅▄▅▅▃▄▁▃▄▅▁▂█▂▃▅▃▇▇▂▄▇▃▄▅</td></tr><tr><td>Zebra Consistency</td><td>▄▃▂▂▁▃▃▂▃▃▂█▃▄▂▃▄▃▁▅▂▃▃▄▆▃▃▄▁▃▃▄▃▂▃▂▂▂▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Batch index</td><td>1000</td></tr><tr><td>Discriminator Horse</td><td>0.32296</td></tr><tr><td>Discriminator Zebra</td><td>0.30181</td></tr><tr><td>Generator Horse</td><td>0.32477</td></tr><tr><td>Generator Zebra</td><td>0.41036</td></tr><tr><td>Horse Consistency</td><td>0.09756</td></tr><tr><td>Zebra Consistency</td><td>0.13619</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">volcanic-sun-39</strong> at: <a href='https://wandb.ai/duckyhome/Horse_vs_Zebra_Transfer/runs/myevemws' target=\"_blank\">https://wandb.ai/duckyhome/Horse_vs_Zebra_Transfer/runs/myevemws</a><br/> View project at: <a href='https://wandb.ai/duckyhome/Horse_vs_Zebra_Transfer' target=\"_blank\">https://wandb.ai/duckyhome/Horse_vs_Zebra_Transfer</a><br/>Synced 5 W&B file(s), 75 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240410_035555-myevemws/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:myevemws). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240410_040704-nx7iah00</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/duckyhome/Horse_vs_Zebra_Transfer/runs/nx7iah00' target=\"_blank\">wandering-shape-40</a></strong> to <a href='https://wandb.ai/duckyhome/Horse_vs_Zebra_Transfer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/duckyhome/Horse_vs_Zebra_Transfer' target=\"_blank\">https://wandb.ai/duckyhome/Horse_vs_Zebra_Transfer</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/duckyhome/Horse_vs_Zebra_Transfer/runs/nx7iah00' target=\"_blank\">https://wandb.ai/duckyhome/Horse_vs_Zebra_Transfer/runs/nx7iah00</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "pgMLl1Xi_xOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/Datasets/HORSE vs. ZEBRA/horse2zebra.zip\"\n",
        "with zipfile.ZipFile(DATASET_PATH, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content\")"
      ],
      "metadata": {
        "id": "33qaxnHFJDhu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2()\n",
        "    ],\n",
        "    additional_targets={\"image0\": \"image\"},\n",
        ")\n",
        "\n",
        "class HorseZebraDataset(Dataset):\n",
        "    def __init__(self, horse_path, zebra_path, transform=None):\n",
        "        self.horse_path = horse_path\n",
        "        self.zebra_path = zebra_path\n",
        "        self.transform = transform\n",
        "\n",
        "        self.horse_images = os.listdir(horse_path)\n",
        "        self.zebra_images = os.listdir(zebra_path)\n",
        "\n",
        "        self.horse_len = len(self.horse_images)\n",
        "        self.zebra_len = len(self.zebra_images)\n",
        "        self.length_dataset = max(self.horse_len, self.zebra_len)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        horse_image = self.horse_images[index % self.horse_len]\n",
        "        zebra_image = self.zebra_images[index % self.zebra_len]\n",
        "\n",
        "        horse_image_path = os.path.join(self.horse_path, horse_image)\n",
        "        zebra_image_path = os.path.join(self.zebra_path, zebra_image)\n",
        "\n",
        "        horse_array = np.array(Image.open(horse_image_path).convert(\"RGB\"))\n",
        "        zebra_array = np.array(Image.open(zebra_image_path).convert(\"RGB\"))\n",
        "\n",
        "        if self.transform:\n",
        "            augmentations = self.transform(image=horse_array, image0=zebra_array)\n",
        "            horse_array = augmentations[\"image\"]\n",
        "            zebra_array = augmentations[\"image0\"]\n",
        "\n",
        "        return horse_array, zebra_array"
      ],
      "metadata": {
        "id": "GLaYeg-o_w1R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator"
      ],
      "metadata": {
        "id": "Qd9pbTqO9Nb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, first_block=False, **kwargs):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, **kwargs, padding_mode='reflect', bias=True),\n",
        "            nn.InstanceNorm2d(out_channels) if not first_block else nn.Identity(),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            DBlock(3, config.FEATURES, first_block=True, kernel_size=4, stride=2, padding=1), # (3, 256, 256) -> (64, 128, 128)\n",
        "            DBlock(config.FEATURES*1, config.FEATURES*2, kernel_size=4, stride=2, padding=1), # (128, 64, 64)\n",
        "            DBlock(config.FEATURES*2, config.FEATURES*4, kernel_size=4, stride=2, padding=1), # (256, 32, 32)\n",
        "            DBlock(config.FEATURES*4, config.FEATURES*8, kernel_size=4, stride=1, padding=1), # (512, 31, 31)\n",
        "        )\n",
        "        self.last_layer = nn.Sequential(\n",
        "            nn.Conv2d(config.FEATURES*8, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"), # (1, 30, 30)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3, 256, 256)\n",
        "        x = self.model(x)\n",
        "        x = self.last_layer(x)\n",
        "        return x\n",
        "\n",
        "def test():\n",
        "    model = Discriminator()\n",
        "    x = torch.randn((5, 3, 256, 256))\n",
        "    preds = model(x)\n",
        "    print(preds.shape)\n",
        "    print(torchsummary.summary(model.to(config.DEVICE), (3, 256, 256)))\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLUNv4YesBXT",
        "outputId": "235dd12e-ab53-4689-9b67-515dfb7f219e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1, 30, 30])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           3,136\n",
            "          Identity-2         [-1, 64, 128, 128]               0\n",
            "         LeakyReLU-3         [-1, 64, 128, 128]               0\n",
            "            DBlock-4         [-1, 64, 128, 128]               0\n",
            "            Conv2d-5          [-1, 128, 64, 64]         131,200\n",
            "    InstanceNorm2d-6          [-1, 128, 64, 64]               0\n",
            "         LeakyReLU-7          [-1, 128, 64, 64]               0\n",
            "            DBlock-8          [-1, 128, 64, 64]               0\n",
            "            Conv2d-9          [-1, 256, 32, 32]         524,544\n",
            "   InstanceNorm2d-10          [-1, 256, 32, 32]               0\n",
            "        LeakyReLU-11          [-1, 256, 32, 32]               0\n",
            "           DBlock-12          [-1, 256, 32, 32]               0\n",
            "           Conv2d-13          [-1, 512, 31, 31]       2,097,664\n",
            "   InstanceNorm2d-14          [-1, 512, 31, 31]               0\n",
            "        LeakyReLU-15          [-1, 512, 31, 31]               0\n",
            "           DBlock-16          [-1, 512, 31, 31]               0\n",
            "           Conv2d-17            [-1, 1, 30, 30]           8,193\n",
            "          Sigmoid-18            [-1, 1, 30, 30]               0\n",
            "================================================================\n",
            "Total params: 2,764,737\n",
            "Trainable params: 2,764,737\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 71.03\n",
            "Params size (MB): 10.55\n",
            "Estimated Total Size (MB): 82.33\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ],
      "metadata": {
        "id": "l1clifWU9Pd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, **kwargs, padding_mode=\"reflect\") if down else\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True) if use_act else nn.Identity()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            GBlock(channels, channels, use_act=True, kernel_size=3, stride=1, padding=1),\n",
        "            GBlock(channels, channels, use_act=False, kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, num_residuals=9):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(3, config.FEATURES, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"), # (3, 256, 256) -> (64, 256, 256)\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.down_block = nn.Sequential(\n",
        "            GBlock(config.FEATURES*1, config.FEATURES*2, kernel_size=3, stride=2, padding=1), # (128, 128, 128)\n",
        "            GBlock(config.FEATURES*2, config.FEATURES*4, kernel_size=3, stride=2, padding=1), # (256, 64, 64)\n",
        "        )\n",
        "\n",
        "        self.residual_block = nn.Sequential(\n",
        "            *[ResidualBlock(config.FEATURES*4) for _ in range(num_residuals)]\n",
        "        )\n",
        "\n",
        "        self.up_block = nn.Sequential(\n",
        "            GBlock(config.FEATURES*4, config.FEATURES*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            # (128, 128, 128)\n",
        "            GBlock(config.FEATURES*2, config.FEATURES*1, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            # (64, 256, 256)\n",
        "        )\n",
        "\n",
        "        self.last = nn.Sequential(\n",
        "            nn.Conv2d(config.FEATURES, 3, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"), # (3, 256, 256)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        x = self.down_block(x)\n",
        "        x = self.residual_block(x)\n",
        "        x = self.up_block(x)\n",
        "        x = self.last(x)\n",
        "        return x\n",
        "\n",
        "def test():\n",
        "    model = Generator()\n",
        "    x = torch.randn((5, 3, 256, 256))\n",
        "    preds = model(x)\n",
        "    print(preds.shape)\n",
        "    print(torchsummary.summary(model.to(config.DEVICE), (3, 256, 256)))\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7xcecWvwPbm",
        "outputId": "2b1ed3bb-bf6d-419b-a053-032e98090ae1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3, 256, 256])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 256, 256]           9,472\n",
            "              ReLU-2         [-1, 64, 256, 256]               0\n",
            "            Conv2d-3        [-1, 128, 128, 128]          73,856\n",
            "    InstanceNorm2d-4        [-1, 128, 128, 128]               0\n",
            "              ReLU-5        [-1, 128, 128, 128]               0\n",
            "            GBlock-6        [-1, 128, 128, 128]               0\n",
            "            Conv2d-7          [-1, 256, 64, 64]         295,168\n",
            "    InstanceNorm2d-8          [-1, 256, 64, 64]               0\n",
            "              ReLU-9          [-1, 256, 64, 64]               0\n",
            "           GBlock-10          [-1, 256, 64, 64]               0\n",
            "           Conv2d-11          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-12          [-1, 256, 64, 64]               0\n",
            "             ReLU-13          [-1, 256, 64, 64]               0\n",
            "           GBlock-14          [-1, 256, 64, 64]               0\n",
            "           Conv2d-15          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-16          [-1, 256, 64, 64]               0\n",
            "         Identity-17          [-1, 256, 64, 64]               0\n",
            "           GBlock-18          [-1, 256, 64, 64]               0\n",
            "    ResidualBlock-19          [-1, 256, 64, 64]               0\n",
            "           Conv2d-20          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-21          [-1, 256, 64, 64]               0\n",
            "             ReLU-22          [-1, 256, 64, 64]               0\n",
            "           GBlock-23          [-1, 256, 64, 64]               0\n",
            "           Conv2d-24          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-25          [-1, 256, 64, 64]               0\n",
            "         Identity-26          [-1, 256, 64, 64]               0\n",
            "           GBlock-27          [-1, 256, 64, 64]               0\n",
            "    ResidualBlock-28          [-1, 256, 64, 64]               0\n",
            "           Conv2d-29          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-30          [-1, 256, 64, 64]               0\n",
            "             ReLU-31          [-1, 256, 64, 64]               0\n",
            "           GBlock-32          [-1, 256, 64, 64]               0\n",
            "           Conv2d-33          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-34          [-1, 256, 64, 64]               0\n",
            "         Identity-35          [-1, 256, 64, 64]               0\n",
            "           GBlock-36          [-1, 256, 64, 64]               0\n",
            "    ResidualBlock-37          [-1, 256, 64, 64]               0\n",
            "           Conv2d-38          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-39          [-1, 256, 64, 64]               0\n",
            "             ReLU-40          [-1, 256, 64, 64]               0\n",
            "           GBlock-41          [-1, 256, 64, 64]               0\n",
            "           Conv2d-42          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-43          [-1, 256, 64, 64]               0\n",
            "         Identity-44          [-1, 256, 64, 64]               0\n",
            "           GBlock-45          [-1, 256, 64, 64]               0\n",
            "    ResidualBlock-46          [-1, 256, 64, 64]               0\n",
            "           Conv2d-47          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-48          [-1, 256, 64, 64]               0\n",
            "             ReLU-49          [-1, 256, 64, 64]               0\n",
            "           GBlock-50          [-1, 256, 64, 64]               0\n",
            "           Conv2d-51          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-52          [-1, 256, 64, 64]               0\n",
            "         Identity-53          [-1, 256, 64, 64]               0\n",
            "           GBlock-54          [-1, 256, 64, 64]               0\n",
            "    ResidualBlock-55          [-1, 256, 64, 64]               0\n",
            "           Conv2d-56          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-57          [-1, 256, 64, 64]               0\n",
            "             ReLU-58          [-1, 256, 64, 64]               0\n",
            "           GBlock-59          [-1, 256, 64, 64]               0\n",
            "           Conv2d-60          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-61          [-1, 256, 64, 64]               0\n",
            "         Identity-62          [-1, 256, 64, 64]               0\n",
            "           GBlock-63          [-1, 256, 64, 64]               0\n",
            "    ResidualBlock-64          [-1, 256, 64, 64]               0\n",
            "           Conv2d-65          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-66          [-1, 256, 64, 64]               0\n",
            "             ReLU-67          [-1, 256, 64, 64]               0\n",
            "           GBlock-68          [-1, 256, 64, 64]               0\n",
            "           Conv2d-69          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-70          [-1, 256, 64, 64]               0\n",
            "         Identity-71          [-1, 256, 64, 64]               0\n",
            "           GBlock-72          [-1, 256, 64, 64]               0\n",
            "    ResidualBlock-73          [-1, 256, 64, 64]               0\n",
            "           Conv2d-74          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-75          [-1, 256, 64, 64]               0\n",
            "             ReLU-76          [-1, 256, 64, 64]               0\n",
            "           GBlock-77          [-1, 256, 64, 64]               0\n",
            "           Conv2d-78          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-79          [-1, 256, 64, 64]               0\n",
            "         Identity-80          [-1, 256, 64, 64]               0\n",
            "           GBlock-81          [-1, 256, 64, 64]               0\n",
            "    ResidualBlock-82          [-1, 256, 64, 64]               0\n",
            "           Conv2d-83          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-84          [-1, 256, 64, 64]               0\n",
            "             ReLU-85          [-1, 256, 64, 64]               0\n",
            "           GBlock-86          [-1, 256, 64, 64]               0\n",
            "           Conv2d-87          [-1, 256, 64, 64]         590,080\n",
            "   InstanceNorm2d-88          [-1, 256, 64, 64]               0\n",
            "         Identity-89          [-1, 256, 64, 64]               0\n",
            "           GBlock-90          [-1, 256, 64, 64]               0\n",
            "    ResidualBlock-91          [-1, 256, 64, 64]               0\n",
            "  ConvTranspose2d-92        [-1, 128, 128, 128]         295,040\n",
            "   InstanceNorm2d-93        [-1, 128, 128, 128]               0\n",
            "             ReLU-94        [-1, 128, 128, 128]               0\n",
            "           GBlock-95        [-1, 128, 128, 128]               0\n",
            "  ConvTranspose2d-96         [-1, 64, 256, 256]          73,792\n",
            "   InstanceNorm2d-97         [-1, 64, 256, 256]               0\n",
            "             ReLU-98         [-1, 64, 256, 256]               0\n",
            "           GBlock-99         [-1, 64, 256, 256]               0\n",
            "          Conv2d-100          [-1, 3, 256, 256]           9,411\n",
            "            Tanh-101          [-1, 3, 256, 256]               0\n",
            "================================================================\n",
            "Total params: 11,378,179\n",
            "Trainable params: 11,378,179\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 1003.00\n",
            "Params size (MB): 43.40\n",
            "Estimated Total Size (MB): 1047.15\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main training"
      ],
      "metadata": {
        "id": "SSIP6IWJpItb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Losses\n",
        "l1 = nn.L1Loss()\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "# Instantiate dataset and dataloader\n",
        "HORSE_PATH = \"/content/horse2zebra/train/horse\"\n",
        "ZEBRA_PATH = \"/content/horse2zebra/train/zebra\"\n",
        "CHECKPOINT_DIR = \"/content/drive/MyDrive/GANs/Horse to Zebra CycleGAN/Checkpoints\"\n",
        "dataset = HorseZebraDataset(horse_path=HORSE_PATH, zebra_path=ZEBRA_PATH, transform=transform)\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=config.NUM_WORKERS\n",
        ")"
      ],
      "metadata": {
        "id": "klGE4uH0pISZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"Horse_vs_Zebra_Transfer\", config=config)\n",
        "\n",
        "# Instantiate models\n",
        "disc_H = Discriminator().to(config.DEVICE) # Classify horse images as real or fake\n",
        "disc_Z = Discriminator().to(config.DEVICE) # Classify zebra images as real or fake\n",
        "gen_H = Generator().to(config.DEVICE) # Generate horse images\n",
        "gen_Z = Generator().to(config.DEVICE) # Generate zebra images\n",
        "\n",
        "# Optimizers\n",
        "optim_disc = optim.Adam(\n",
        "    list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
        "    lr=config.LEARNING_RATE,\n",
        "    betas=(0.5, 0.999)\n",
        ")\n",
        "optim_gen = optim.Adam(\n",
        "    list(gen_H.parameters()) + list(gen_Z.parameters()),\n",
        "    lr=config.LEARNING_RATE,\n",
        "    betas=(0.5, 0.999)\n",
        ")\n",
        "\n",
        "last_epoch = -1\n",
        "\n",
        "load_checkpoint = False\n",
        "if load_checkpoint:\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f'checkpoint_epoch_{last_epoch}.pt')\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    # Load the models\n",
        "    gen_H.load_state_dict(checkpoint['gen_H_state_dict'])\n",
        "    gen_Z.load_state_dict(checkpoint['gen_Z_state_dict'])\n",
        "    disc_H.load_state_dict(checkpoint['disc_H_state_dict'])\n",
        "    disc_Z.load_state_dict(checkpoint['disc_Z_state_dict'])\n",
        "\n",
        "    # Load the optimizers\n",
        "    optim_gen.load_state_dict(checkpoint['optim_gen_state_dict'])\n",
        "    optim_disc.load_state_dict(checkpoint['optim_disc_state_dict'])\n",
        "\n",
        "    # Get other information from the checkpoint if needed\n",
        "    last_epoch = checkpoint['last_epoch']\n",
        "\n",
        "# Main train\n",
        "\n",
        "d_scaler = torch.cuda.amp.GradScaler()\n",
        "g_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch in range(last_epoch+1, config.EPOCHS):\n",
        "    loop = tqdm.tqdm(loader, leave=True)\n",
        "    loop.set_description(f\"Epoch {epoch}\")\n",
        "    for step, (horse, zebra) in enumerate(loop):\n",
        "        horse = horse.to(config.DEVICE)\n",
        "        zebra = zebra.to(config.DEVICE)\n",
        "\n",
        "        ### Discriminators ###\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # Horse\n",
        "            fake_horse = gen_H(zebra)\n",
        "            real_H_preds = disc_H(horse)\n",
        "            fake_H_preds = disc_H(fake_horse.detach())\n",
        "\n",
        "            D_real_H_loss = mse(real_H_preds, torch.ones_like(real_H_preds))\n",
        "            D_fake_H_loss = mse(fake_H_preds, torch.zeros_like(fake_H_preds))\n",
        "            D_H_loss = D_real_H_loss + D_fake_H_loss\n",
        "\n",
        "            # Zebra\n",
        "            fake_zebra = gen_Z(horse)\n",
        "            real_Z_preds = disc_Z(zebra)\n",
        "            fake_Z_preds = disc_Z(fake_zebra.detach())\n",
        "\n",
        "            D_real_Z_loss = mse(real_Z_preds, torch.ones_like(real_Z_preds))\n",
        "            D_fake_Z_loss = mse(fake_Z_preds, torch.zeros_like(fake_Z_preds))\n",
        "            D_Z_loss = D_real_Z_loss + D_fake_Z_loss\n",
        "\n",
        "            # Put those 2 losses together\n",
        "            D_loss = (D_H_loss + D_Z_loss) / 2\n",
        "\n",
        "        # Backpropagation on disciminators\n",
        "        optim_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(optim_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        ### Train generators ###\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_H_preds = disc_H(fake_horse)\n",
        "            fake_Z_preds = disc_Z(fake_zebra)\n",
        "            G_H_loss = mse(fake_H_preds, torch.ones_like(fake_H_preds))\n",
        "            G_Z_loss = mse(fake_Z_preds, torch.ones_like(fake_Z_preds))\n",
        "\n",
        "            # Cycle Loss\n",
        "            cycle_horse = gen_H(fake_zebra)\n",
        "            cycle_zebra = gen_Z(fake_horse)\n",
        "            consistency_H_loss = l1(horse, cycle_horse)\n",
        "            consistency_Z_loss = l1(zebra, cycle_zebra)\n",
        "\n",
        "            # Identity loss\n",
        "            # identity_horse = gen_H(horse)\n",
        "            # identity_zebra = gen_Z(zebra)\n",
        "            # identity_H_loss = l1(horse, identity_horse)\n",
        "            # identity_Z_loss = l1(zebra, identity_zebra)\n",
        "\n",
        "            # Put them together\n",
        "            G_loss = (\n",
        "                G_H_loss +\n",
        "                G_Z_loss +\n",
        "                consistency_H_loss * config.LAMBDA_CONSISTENCY +\n",
        "                consistency_Z_loss * config.LAMBDA_CONSISTENCY\n",
        "                # identity_H_loss * config.LAMBDA_IDENTITY +\n",
        "                # identity_Z_loss * config.LAMBDA_IDENTITY\n",
        "            )\n",
        "\n",
        "        # Backpropagation on generators\n",
        "        optim_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(optim_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        if step % 50 == 0:\n",
        "            with torch.no_grad():\n",
        "                wandb.log({\n",
        "                    \"Discriminator Horse\": D_H_loss.item(),\n",
        "                    \"Discriminator Zebra\": D_Z_loss.item(),\n",
        "                    \"Generator Horse\": G_H_loss.item(),\n",
        "                    \"Generator Zebra\": G_Z_loss.item(),\n",
        "                    \"Horse Consistency\": consistency_H_loss.item(),\n",
        "                    \"Zebra Consistency\": consistency_Z_loss.item(),\n",
        "                    \"Batch index\": step\n",
        "                })\n",
        "\n",
        "                row1_grid = vutils.make_grid([horse[0], fake_zebra[0], cycle_horse[0]], normalize=True).cpu().permute(1, 2, 0).numpy()\n",
        "                row2_grid = vutils.make_grid([zebra[0], fake_horse[0], cycle_zebra[0]], normalize=True).cpu().permute(1, 2, 0).numpy()\n",
        "                merged_grid = np.concatenate((row1_grid, row2_grid), axis=0)\n",
        "\n",
        "                wandb.log({\n",
        "                    \"Generated images\": wandb.Image(merged_grid),\n",
        "                })\n",
        "\n",
        "    last_epoch = epoch\n",
        "    # Save checkpoint after each epoch\n",
        "    # current_run_name = wandb.run.name\n",
        "    # checkpoint_path = os.path.join(CHECKPOINT_DIR, current_run_name)\n",
        "    # os.mkdir(checkpoint_path)\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f'checkpoint_epoch_{epoch}.pt')\n",
        "    torch.save({\n",
        "        'last_epoch': epoch,\n",
        "        'gen_H_state_dict': gen_H.state_dict(),\n",
        "        'gen_Z_state_dict': gen_Z.state_dict(),\n",
        "        'disc_H_state_dict': disc_H.state_dict(),\n",
        "        'disc_Z_state_dict': disc_Z.state_dict(),\n",
        "        'optim_gen_state_dict': optim_gen.state_dict(),\n",
        "        'optim_disc_state_dict': optim_disc.state_dict(),\n",
        "    }, checkpoint_path)\n",
        "    print(\"==> Saved checkpoint.\")"
      ],
      "metadata": {
        "id": "CWCX5F54r2bs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc00e17d-e45a-413c-b63a-b306e032684b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 1334/1334 [03:43<00:00,  5.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 1334/1334 [03:43<00:00,  5.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 1334/1334 [03:43<00:00,  5.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 1334/1334 [03:42<00:00,  5.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 1334/1334 [03:43<00:00,  5.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 1334/1334 [03:45<00:00,  5.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 1334/1334 [03:44<00:00,  5.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 1334/1334 [03:43<00:00,  5.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 1334/1334 [03:44<00:00,  5.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 1334/1334 [03:44<00:00,  5.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 1334/1334 [03:43<00:00,  5.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 1334/1334 [03:44<00:00,  5.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 1334/1334 [03:44<00:00,  5.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 1334/1334 [03:44<00:00,  5.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 1334/1334 [03:44<00:00,  5.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 1334/1334 [03:44<00:00,  5.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 1334/1334 [03:45<00:00,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 1334/1334 [03:45<00:00,  5.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 1334/1334 [03:45<00:00,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 1334/1334 [03:44<00:00,  5.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 1334/1334 [03:45<00:00,  5.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 1334/1334 [03:44<00:00,  5.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23:  41%|████      | 547/1334 [01:32<02:06,  6.21it/s]"
          ]
        }
      ]
    }
  ]
}